{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:03:41.458512Z",
     "start_time": "2024-04-14T17:03:39.116063Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets.clean_noisy_dataset import CleanNoisyDataset\n",
    "from utils.file_utils import get_file_paths"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO download source files in ../audio_data\n",
    "# TODO generate metadata file\n",
    "# TODO install ffmpeg\n",
    "\n",
    "data_dir = '../_audio_data'\n",
    "sound_dir = '/UrbanSound8K/audio'\n",
    "metadata_path = 'target/common_voice_metadata.tsv'\n",
    "\n",
    "output_dir = '../_datasets/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file_name = output_dir + \"clean_noisy_dataset.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:03:41.461964Z",
     "start_time": "2024-04-14T17:03:41.459758Z"
    }
   },
   "id": "b3adc5281ecfcb1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "clean_metadata = pd.read_csv(metadata_path, delimiter='\\t')\n",
    "clean_metadata['abs_path'] = os.path.abspath(data_dir) + '/' + clean_metadata['path']\n",
    "clean_files = clean_metadata['abs_path'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:03:41.477399Z",
     "start_time": "2024-04-14T17:03:41.462783Z"
    }
   },
   "id": "556b6af213a33197",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "sounds_path = os.path.abspath(data_dir + sound_dir)\n",
    "sound_files = get_file_paths([sounds_path], 'wav')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:03:41.495328Z",
     "start_time": "2024-04-14T17:03:41.478224Z"
    }
   },
   "id": "38c6fd8e02fc584d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = CleanNoisyDataset(clean_files, sound_files, 5000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:09:00.660693Z",
     "start_time": "2024-04-14T17:03:41.496954Z"
    }
   },
   "id": "1c5cde17798d5e48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files from 5000\n",
      "Processed 100 files from 5000\n",
      "Processed 200 files from 5000\n",
      "Processed 300 files from 5000\n",
      "Processed 400 files from 5000\n",
      "Processed 500 files from 5000\n",
      "Processed 600 files from 5000\n",
      "Processed 700 files from 5000\n",
      "Processed 800 files from 5000\n",
      "Processed 900 files from 5000\n",
      "Processed 1000 files from 5000\n",
      "Processed 1100 files from 5000\n",
      "Processed 1200 files from 5000\n",
      "Processed 1300 files from 5000\n",
      "Processed 1400 files from 5000\n",
      "Processed 1500 files from 5000\n",
      "Processed 1600 files from 5000\n",
      "Processed 1700 files from 5000\n",
      "Processed 1800 files from 5000\n",
      "Processed 1900 files from 5000\n",
      "Processed 2000 files from 5000\n",
      "Processed 2100 files from 5000\n",
      "Processed 2200 files from 5000\n",
      "Processed 2300 files from 5000\n",
      "Processed 2400 files from 5000\n",
      "Processed 2500 files from 5000\n",
      "Processed 2600 files from 5000\n",
      "Processed 2700 files from 5000\n",
      "Processed 2800 files from 5000\n",
      "Processed 2900 files from 5000\n",
      "Processed 3000 files from 5000\n",
      "Processed 3100 files from 5000\n",
      "Processed 3200 files from 5000\n",
      "Processed 3300 files from 5000\n",
      "Processed 3400 files from 5000\n",
      "Processed 3500 files from 5000\n",
      "Processed 3600 files from 5000\n",
      "Processed 3700 files from 5000\n",
      "Processed 3800 files from 5000\n",
      "Processed 3900 files from 5000\n",
      "Processed 4000 files from 5000\n",
      "Processed 4100 files from 5000\n",
      "Processed 4200 files from 5000\n",
      "Processed 4300 files from 5000\n",
      "Processed 4400 files from 5000\n",
      "Processed 4500 files from 5000\n",
      "Processed 4600 files from 5000\n",
      "Processed 4700 files from 5000\n",
      "Processed 4800 files from 5000\n",
      "Processed 4900 files from 5000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(dataset, output_file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T17:09:15.834676Z",
     "start_time": "2024-04-14T17:09:00.661889Z"
    }
   },
   "id": "746773aceb6a9642",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
